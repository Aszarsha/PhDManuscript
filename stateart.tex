\chapter{State of the art}
\label{chap:state}

%QUOTE XXX We make our world significant by the courage of our questions and by the depth of your answers. Carl Sagan QUOTE XXX

\section{Biological databases}
	\subsection{Networks}

	Increasingly advanced experimental methods are used to provide evidence of existing interactions.
	Nowadays, comprehensive litterature combined with advanced text mining capabilities further advance cross-references between biological products.
	Available resources that provide access to this knowledge are currently accessible from many only databases.

	Two major classes of databases exists: the automatically referenced database \parencite{szklarczyk2014string}, and the manually currated databases \parencite{orchard2012protein}.

	\subsection{Orthologous genes}
%	\label{subsec:orthology}
%
	In their seminal paper, \parencite{tatusov1997genomic} constructed ''clusters of orthologous genes'' (COG) across multiple species.
	They contain similar cross-species sequences as well as similar intra-species sequences, i.e. paralogous sequences.

	The Inparanoid database \parencite{obrien2005inparanoid} is a publictly available orthology database that contains pairwise ortholog groups of more than 273 organisms\footnote{\url{http://inparanoid.sbc.su.se}, Release 8.0, December 2013}.
%	COG => PPI networks alignment (difficult problem \parencite{el2011lagrangian}).

%	\Textcite{mccune2012using} provide an overview of homology based techniques for the discovery of evolutionary event.


%	Most orthologous sequence detection techniques are directly based on sequence comparison.
%	However, \parencite{bandyopadhyay2006systematic} integrate with brute force PPI topology analysis across species to infer functional similarity and evolutionary conservation.
%
%
%	Orthology information can effectively be represented as a $k$-partite graph between $k$ species.
%
%	XXX in conclusion, use those functionally similar as bipartite ? XXX
%
%	\subsection{Network analysis}

\section{Statistical analysis of gene expression}

	Nowadays, differential analysis of transcriptomic profiles is ubiquitous in molecular biology.
	The ability to broadly assey biomolecular profiles of multiple samples cheaply enabled the wide adoption of techniques based on the differential analysis of multiple whole-genome samples.
	Indeed, genes for which their expression profiles are correlated over many different conditions are very likely to be involved in the same processes or to exhibit similar functionalities \parencite{ideker2002discovering}.
	On the other hand, genes with significantly different expression profiles under conditions are candidates for choice as biomarkers for the biological phenomenons under study \parencite{altman2001whole}.

	For example in cancer research, the ability measure transcriptomic state within a cell is a central technique for the analysis of mutated cell biomolecular machinery.
	Indeed, in order to maximize therapeutic effect of treatment and minimize side effects, it is important to be able to characterize the genetic profiles of distinct tumor types.
	For a long time, tumor classification was based on medical expertise and assessment based on the clinical evolution and on the physical appearance of either the cancerous growth or its cells.
	However, even for tumor of the same type and grade, widely different clinical development and outcome were observed.
	A technique allowing for the classification and the detection of cancer types and subtypes was dearly needed.

	The advances of gene expression profiling techniques allowed \textcite{golub1999molecular} to develop such a classification technique based on simple statistical testing: the final prediction is the class for which the sum of scores computed statistically for each genes\footnote{They actually compute the score only for genes that they consider \emph{informative}, even though they acknowledge this selection as "somewhat arbitrary".} is maximal.

%	XXX

	Whole cell expression profiles can be used to classify cancer tumors, and further predict patient clinical outcome \parencites{perou2000molecular}{sorlie2001gene}{vantveer2002gene}{vijver2002gene}.
	Moreover, \textcite{ross2000systematic} showed that gene profiles can be directly linked to their cell line's origin through consistent correspondence between gene expression patterns and origin of the tissue.
	Even though the literature in the domain is quite extensive, recent studies such as \parencite{estevez2015gene} still uses DNA chip for genes expression profiling.

%	Even though transcriptome analysis is widespread in cancer research, it allows for many different applications. XXX List other applications: antibiotic treatment, ... XXX

	One important limitation of these studies, however, is that they are based on gene-centric methods, which use univariate statistical testing to call for significantly differentially expressed genes.
	Modern approaches integrate knowledge for many different database.

\subsection{Cross-species analysis}

	Several authors identified the benefits of combining cross-species experimental data.
	At the single gene level, \textcite{noort2003predicting} have demonstrated that conserved co-expression is a strong co-evolutionary signal.
	More recent studies suggested to identify conserved biological processes.

	\Textcite{reiss2006integrated} recognize that co-expression of genes is not enough information for the discovery of the underlying genetic regulatory process.
	They suggest that co-regulation is a better criteria for detection, and show that a biclustering of the data over both gene expression and condition provide more sensible results.
	The optimization objective that they propose is an ad-hoc multi-criteria objective that takes into account transcript co-expression, as well as putative \emph{cis}-acting gene regulatory motifs and connectivity between functionally associated clustered genes.
	They do not provide any new method to solve the biclustering problem, which they acknowledge as being NP-hard problem \parencite{cheng2000biclustering}, and rather implement a local-search heuristic that implicitly look for the Pareto front created by their criteria \parencite{van2003multi}.

	\Textcite{lu2009cross} analyzed transcriptomic profiles of human and mouse macrophages and dendritic cells, under two conditions, to derive common response genes involved in innate immunity.
	They used a probabilistic graphical model that propagates information for each gene about its involvement in the innate immunity response across species or cell types and conditions then seeks pathway enriched with those common responses genes.

	\Textcite{waltman2010multi} presented a multi-species integrative method to heuristically identify conserved biclusters.
	In their setting, a conserved bicluster is a subset of orthologous genes and a subset of conditions that achieve a high score with respect to co-expression, motif co-occurrence and network density.

	\Textcite{kristiansson2013novel} proposed a method for the analysis of gene expression data that takes the homology structure between the different species into account.
	Their method is an extension of the standard Fisher's method for meta-analysis \parencites{hu2006statistical}{campain2010comparison}{tseng2012comprehensive} that explicitly account for in-paralagous and orthologous genes and is able to call differential expression with increased statistical power when compared to methods ignoring this relationship.

	\Textcite{dede2014triclust} introduced a method that finds triclusters consisting of genes that are coexpressed across a subset of samples and a subset of species.

	\Textcite{reiss2015cmonkey2} updated their cMonkey algorithm \parencite{reiss2006integrated} to address the ''long run-time, complexities, and inefficiencies'' of the previous implementation.
	In addition to updating the scoring of the multiple criteria of their objective function, the main addition of this paper is the implementation of a global optimization algorithm for this objective, modeled after a standard $k$-means clustering of biological networks \parencite{watts1998collective}.


\section{Connected active modules}

%There exists mostly two approaches to use biological networks to detect interesting biological processes.
%The first category is composed of \emph{comparative} approaches of the networks structures, that enables to compare networks from different species or of the same species but under different conditions.
%They are treated in \cref{subsec:topomodules}.
%The second category is composed of techniques that aim to select sets of genes in specific biological contexts.
%These techniques usually combine both biological network structures and experimental data, and are called \emph{integrative} approaches since they combine data of different types into a single algorithm.
%They are treated in \cref{subsec:activemodules}.

%\subsection{Topological modules}
%\label{subsec:topomodules}
%
%	This section present methods that use the networks in themselves to extract structures deemed interesting.
%	In order to do so, they use the topological structures of the networks to detect substructures. %that are known to appear in targeted biological function.
%
%	\Textcite{sharan2006modeling} identify three broad types of such approaches: network alignment, network integration, and network querying methods.
%	Even though what they call network integration is an important category of networks comparison problems, which are used for example for protein interaction prediction \parencite{rhodes2005probabilistic} or for protein modules detection \parencites{kelley2005systematic}{zhang2005biology}, it is unrelated from our core problem.
%
%	What they name networks alignments and networks querying problems are two closely related categories of problems.
%	In general terms, graph alignments are made of two seemingly similar subproblems: the \emph{local graph alignment} problem, and the \emph{global graph alignment} problem.
%	Precisely, in the local alignment problem we look for a subgraph in the larger input that most closely resemble a query graph or query criteria.
%	In the global alignment problem we try to match every nodes of one graph to every nodes of the other graph.
%
%	These two subproblem mirror the similarities that exists between the local and global sequence alignment problems.
%	Indeed, similarly to the global sequence alignment problem which is usually used to compare different species or organisms of the same species, the global network alignment problem correspond to the \emph{network alignment} category describe above.
%	And similarly to the local sequence alignment problem which is usually used to compare or locate subsequences, the local network alignment problem correspond to the \emph{network querying} category.
%
%	When looking for matchings networks, vertices are usually mapped on a one-to-one basis, but it can be many-to-one or many-to-many queries.
%	Furthermore, the matching can be weighted, or constrained by a bipartite similarity relationship between the two graphs.
%	They are all optimization problems where some criteria, for example the number of matched nodes or edges, must be maximized.
%
%	These problems pertains to the \emph{module discovery} class of problems over biological networks\footnote{It is also named \emph{community structure discovery} when applied over social networks.}.

%	However, an interesting problem with biological networks is the detection of similar substructures in $k$ different networks.
%	They can either represent different species or the same species in different conditions.
%	The most simple\footnote{But nonetheless difficult, cf. \cref{subsec:netalignment}.} version of the problem is that of topological alignment, but there exists weighted alignment problems that can be used.

%	This section is broken in three independent subsections.
%	First in \cref{subsec:substructure} we present an overview of the topological techniques over biological networks used to infer interesting structures.
%	In \cref{subsec:moduledisc} we provide a detailed look into the module discovery problem, where biological networks and experimental data are combined in order to explain some specific biological process.
%	Finally, in \cref{subsec:netalignment} we look at solutions that look across multiple networks to infer information.
%	In this subsection we will look into technique that explicitly recognize the networks structures through alignment as well as other models.

%\subsection{Active modules}
\label{subsec:activemodules}

	Active modules methods combine biological networks with experimental data, such as expression profiles, to detect network structures of interest for the experiment.
	These methods are well suited to understand single-species processes, since the interpretation of the results usually follows from the inputs.
	They can also be used to look across multiple species for interesting process.

	Already in 2001, \textcite{altman2001whole} recognized the need to use networks of genetic interactions to tackle the analysis of expression data.
	One of the key concepts to understand biological processes in those networks is that of \emph{modules}.
	Modules are considered to be sets of entities, such as genes or proteins, that function in a coordinated fashion or physically interact.
	See \textcite{mitra2013integrative} for an up to date review.

	One possible formulation, for the problem of finding modules within a network, is to look for connected sub-networks that maximize weights on the nodes.
	These weights typically represent some measure of biological activity, for example the expression level of genes.
	In their seminal work, \textcite{ideker2002discovering} were the first to solve the problem of finding gene modules within a biological network, using simulated annealing heuristic optimization.
	They recognize that finding the optimal module (with respect to the sum of the nodes' weights) in a biological network is formally equivalent to the \textsc{maximum-weight connected subgraph} (\mwcs{}) combinatorial optimization problem.
	This problem will be treated in \cref{sec:mwcsproblem}.

	\Textcites{dittrich2008identifying} were the firsts to cast the biologically relevant problem into the unified framework of combinatorial optimization theory. % in a systematical approach.
	By recognizing the theoretical grounds of the \mwcs{} problem, they reduce the overall problem to the very well studied \textsc{prize-collecting steiner-tree} optimization problem and apply an efficient algorithm \parencite{ljubic2006algorithmic} that finds provably optimal solutions to the problem.
	They acknowledge the close relationship between the initial scoring and the exact solution found, and provide a simple additive scoring function that ultimately allows for an easy interpretation of the results.
	%They further provide both ways reductions from \mwcs{} to \pcst{} that 


	\Textcite{yamamoto2009better} apply the \mwcs{} problem to pathway gene networks in order to identify what they call ''source components'', subnetworks that hopefully represent the source of the differential behavior in the data.
	They provide a graph decomposition heuristic to solve the underlying computational problem.

	Building on the Integer Linear Programming formulation proposed by \textcite{dittrich2008identifying} and \textcite{zhao2008uncovering}, \textcite{backes2012integer} provides a new ILP expression for the closely related $k$-cardinality \mwcs{} problem that they solve using a branch-and-cut procedure.
	They test the significance of their results using graph permutation and show that the most significant results are obtained inside a small range of sizes over all their data.

	\Textcite{mitra2013integrative} provides an overview of the many network centric approaches to modular detection of cellular processes.
	In particular they classify modern techniques into four classes: the 'active modules' discovery techhniques, the 'conserved modules' identification across species, 'differential modules' that are simultaneously active under different conditions, and the 'composite modules' that integrate many of the possible interaction type into single unified components.


\subsection{Cross-species connected active modules}

	\Textcite{deshpande2010scalable} developed the \nexus{} algorithm for finding conserved active subnetworks.
	\nexus{} is based on simple notions of activity and orthology and uses a heuristic search strategy.
	The authors use the average fold change of genes in a module as a measure for activity.
	To deal with conservation, they collapse paralogous genes within a cluster of orthologous genes (COG) \parencite{tatusov1997genomic}\footnote{As provided by databases such as Inparanoid \parencite{obrien2005inparanoid}.} into single nodes in the respective networks.
	They find modules using a seed-and-extend greedy heuristic that starts from a pair of orthologous seed nodes and then tries to simultaneously grow the two subnetworks by including pairs of neighboring orthologous genes, taking into account their activity as well as the interaction confidences.
	This strategy enforces a very stringent conservation policy: only modules whose genes are fully conserved are found.
	In addition, the locality of the greedy search strategy impairs the ability to find larger conserved modules and extending the search space around the seed genes drastically increases the runtime.

	In recent work, \textcite{zinman2015moduleblast} introduce \moduleblast{}, a method that, similarly to \nexus{}, represents groups of orthologous proteins as single nodes in a combined network and tries to find connected subnetworks that are differentially expressed.
	The novelty of the method is the classification of the found modules according to the sign of the log fold change expression values.
	By doing so, the authors are able to assess whether conserved active modules show consistent or inconsistent
  expression patterns.
	However \moduleblast{}, like \nexus{}, requires strict conservation of module genes.
	We see that as an important limitation that our present work aim to correct.

%\section{Discrete optimization}
\section{The \textsc{maximum-weight connected subgraph} problem}
\label{sec:mwcsproblem}

	This section is separated in two parts.
	In \cref{subsec:mwcsintro} we first introduce the \textsc{steiner tree}, the \textsc{prize-collecting steiner tree} (\pcst{}), and the \textsc{maximum-weight connected subgraph} (\mwcs{}) problems.
	We also provide the main complexity results for the \mwcs{} problem, and since a number of those results mostly follow from results for the \pcst{} problem, we provide the most important ones for this problem too.
	In \cref{subsec:solvingmwcs} we present the main methods used to solve those problems.
	There are many techniques to solve these problems, and they can be classified to two caterogies.
	The theoretically-sound methods, that can provide either a provably optimal (or a proven gap\footnote{Proven maximal distance to the optimal solution.}) solution, or an approximation solution to a proven bounded-factor.
	And the heuristic methods, that approximate the optimal solution to an unknown factor, but which are usually much faster.

	\subsection{Problems introductions}
	\label{subsec:mwcsintro}

	The \textsc{steiner tree} problem is an extremely well known combinatorial optimization problem, which is part of Karp's original 21 NP-complete problems \parencite{karp1972reducibility}.
	It has its origin in the geometry of Jakob Steiner's eponym Steiner problem, and pertain to the class of mathematical optimization problems over graphs.
	It is informally defined as follows.
	A large number of variations of this problem exists: the \emph{Steiner tree problems}.
	\Textcite{hauptmann2014compendium} maintain an extensive and up-to-date compendium of those variants.

	\paragraph{}
	One of the variants of the \textsc{steiner tree} problem is the \textsc{prize-collecting steiner tree} problem, or \textsc{pcst} problem.
	Is is informally defined as follows.

	\textbf{\pcst{}$\colon$} Given a graph, a non-negative weight for each vertex, and a non-negative cost for each edge, the goal is to find the subtree that maximizes the sum of the weights minus the sum of the costs.

	The \pcst{} problem is an \emph{utility versus cost optimization} variant (as formally defined by \textcite{conrad2007connections}) of the \textsc{steiner tree} problem.
	\Textcite{bienstock1993note} were the firsts to formally introduce the problem, and the first recognized proof of NP-hardness follows from \textcite{camerini1979complexity} (even through the problem was not formally defined at the time).
	As a surprisingly late result\footnote{They themselves acknowledge that this is an easy result \parencite[footnote 12]{feigenbaum2000sharing}.}, \textcite{feigenbaum2000sharing} were the first to prove that the \pcst{} problem is NP-hard to approximate within any constant ratio $0 < \epsilon < 1$, or APX-hard, using a reduction from \textsc{sat}.
	This variant is highly relevant to our context as there exist bidirectional reductions between the \pcst{} and \mwcs{} problems, and for a long time reducing an \mwcs{} instance to a \pcst{} instance was the technique of choice to actually solve the problem (cf. \cref{subsec:solvingmwcs}).

	\paragraph{}
	The \textsc{maximum-weight connected subgraph} problem, or \mwcs{} problem, falls within the same classification as various Steiner tree problems: it is a problem of combinatorial optimization over graphs.
	It is informally defined as follows.

	\textbf{\mwcs{}$\colon$} Given a graph and a real-valued weight for each vertex, the goal is to find the connected subset of vertices that maximizes the sum of the weights.

	First observe that, since the edges are unweighted, the solution is trivial, full or empty, if the vertices' weights are respectively all positive or all negative.
	This is in contrast with the \pcst{} problem where the positive weights of the vertices oppose the costs of the edges.

	From a computer science point of view, the \mwcs{} problem is simple in its definition.
	Nevertheless, it is actually a very difficult problem to solve, and in many cases remains intractable.
	The first text to prove NP-hardness of the problem is the unpublished manuscript from \textcite{vergis1983manuscript}.
	Manuscript that \textcite[Section 5]{johnson1985np} acknowledge when he looked into a series of graph problems in his famous \emph{NP-Completeness Columns}.
	The proof is based on the reduction from the \textsc{steiner tree} problem, provided by \textcite{garey1979computers}.
	Johnson made the fundamental observation that the solution to the \mwcs{} problem can always be reduced to a tree, since the additional edges serve no purpose.
	Karp later provided another proof of NP-hardness for the \mwcs{} problem in \parencite[Supplementary Material]{ideker2002discovering}, by providing a reduction from the \textsc{minimum set cover} problem, another problem which is one of his 21 first NP-complete problems \parencite{karp1972reducibility}.


	Indeed, \textcite{alvarez2013maximum} proved that the \mwcs{} problem is actually APX-hard itself.
	Using the SAT reduction previously mentioned \parencite{feigenbaum2000sharing}, they extended the result to \mwcs{} using a straightforward reduction of \pcst{} to \mwcs{}.

	In the same way the \textsc{steiner tree} broadly defines a large set of related problems, the \mwcs{} problem defines itself a set of closely related problems.
	These problems can be applied in many different contexts, of which: social network sciences, operations research, certainly networks design, and system biology, which is our main interest in this manuscript.

	\paragraph{}
	Based on the basic version of the \mwcs{} problem, the principal variants are the \emph{constrained} versions, with an allocated budget and additional cost assigned to each vertex.
	The \textsc{$k$-cardinality \mwcs{}}, the \textsc{cardinality-constrained \mwcs{}}, and the \textsc{budget-constrained \mwcs{}} serve interesting purposes.
	The \textsc{$k$-cardinality \mwcs{}} require that the solution be comprised of exactly $k$ vertices, whereas the \textsc{cardinality-constrained \mwcs{}} variant require that the solution includes at most $K$ vertices.
	The \textsc{budget-constrained \mwcs{}} variant assigns an additional positive cost to each vertex, and requires that the sum of the costs be at most a given budget $B$.
	Clearly, assigning a positive cost of $1$ for each node of the \textsc{cardinality-constrained \mwcs{}} problem provides a trivial reduction to the \textsc{budget-constrained \mwcs{}} problem.

	Note that for all these constrained versions, the problems remain non-trivial even when the nodes' weights are all positive.
	Furthermore, note that while removing the connectivity constraint in the basic version of the problem makes it trivial, in those variants the problems then become equivalent to the \textsc{0-1 knapsack} problem (which is another one of Karp's original 21 NP-complete problems \parencite{karp1972reducibility}).

	They can all be defined either on graphs or on directed graphs, and there exists rooted variants where one (or multiple) root(s) have to be selected in the solution.

	There also exists minimization variants or reformulations for those problems. Most of them are strictly equivalent from an optimality standpoint: minimizing the sum of the opposite of the nodes' weights.
	However, they differ from approximation standpoint, see \parencites{feigenbaum2000sharing}{johnson2000prize} for details.

	\subsection{\mwcs{} in practice}

		The \mwcs{} problem and its cardinality-constrained and budget-constrained variants are used in numerous important practical applications.

		\Textcite{hochbaum1994node} first described the fixed cardinality variant of the problem (\textsc{$k$-cardinality \mwcs{}}).
		They relate its use in two contexts.
		First in off-shore oil-drilling where each facility is represented by a node and the weight their costs over benefits.
		Second in forest harvesting where we need to find the $k$ connected parcel to harvest considering their associated benefits.
		They call it the \textsc{connected $k$-subgraph} problem.
		They where the first to observe that, for this variant, since adding a constant to the weight of each node does not change the optimal set of nodes, in the optimality context the nodes' weights can all be non-negative.
		They also show that the problem is NP-hard even for bipartite or planar input graphs or if the nodes' weights are boolean.

		\Textcite{lee1998decomposition} reintroduced the \textsc{$k$-cardinality \mwcs{}} problem, and called it simply the \textsc{maximum-weight connected graph} (\textsc{mcg}) problem.
		They were the firsts to introduce the rooted variant where a single root is provided for the solution, that they called the \textsc{constrained mcg} (\textsc{cmcg}).
		They used this rooted variant to provide a decomposition scheme of the \mwcs{} problem into multiple \textsc{cmcg} subproblems.
		They acknowledge that the optimal solution is NP-hard to find, and provide heuristics for their incremental roots selection.
		They use all problems that they introduce in the fiber-optic networks design context.

		Gomes' team looked into the budget constrained version of the problem, both rooted and unrooted variants, that they apply in the context of \emph{conservation planning} \parencites{conrad2007connections}{gomes2008connections}{dilkina2010solving}.

		\Textcite{chen2012efficient} used the \mwcs{} problem to extract signatures from a video stream for the activity detection problem. They represent the video as a three dimentional 6-connect graph, i.e. a space-time matrix, where each node's weights represent video features. They then use standard classifier to classify the signatures.

		\Textcite{carvajal2013imposing} also looked into the forest planning problem to select contiguous regions of forest to maximizes ecosystem protection in nature reserve design, i.e. the number of species and habitats preserved.

		Furthermore, as stated in \cref{subsec:activemodules}, \textcites{dittrich2008identifying}{yamamoto2009better}{backes2012integer}{mitra2013integrative} all used the \mwcs{} problem or its variants in system biology to extract connected sets of genes.


	\subsection{Solving the \mwcs{} problems}
	\label{subsec:solvingmwcs}

	Over the years, many methods have been proposed to solve the \mwcs{} problem.
	They can mostly be categorized into two groups: 1) methods that first reduce the \mwcs{} instance into a \pcst{} instance, or 2) through direct modelization.

	In both groups, many techniques have been proposed in order to make instances easier to solve.
	Instance size reductions are often used, which leads to exact methods if quality guarantees are preserved through reduction, or heuristics (possible approximation) methods when more aggressive simplifications are performed.
	Size reduction algorithms are fundamental techniques in solving large practical Steiner tree problems (or similar, such as the \mwcs{} problem), and applying known exact reduction is the first step for real world instances resolution \parencite{polzin2003algorithms}.

	\subsubsection{Through the Prize-Collecting Steiner Tree problem}

		In their seminal paper, \textcite{goemans1995general} were the firsts to provide an approximation algorithm (a 2-approximation) for a number of \emph{constrained forest} problems, such as the \pcst{} problem.
		They further develop their method in \parencite{goemans1997primal}.
		This is an important contribution since they reformulate the problem into an easy to approximate formulation (the standard formulation is APX-hard), which became the basis for many other contributions afterward.

		Building on these algorithms, \textcite{johnson2000prize} proposed multiple variations of this 2-approximation for \pcst{}, that provide better performance, and application to variants such as the \textsc{quota \pcst{}} where the sum of the weights must be at least a given \emph{quota}, and the \textsc{budget \pcst{}} where the sum of the costs must be at most a given \emph{budget}.

		\Textcite{lucena2004strong} introduces the \emph{generalized subtour elimination constraints} technique, and uses the separation algorithm first described by \textcites{fischetti1994weighted}.

		In two papers, \textcites{ljubic2005solving}{ljubic2006algorithmic} solved the \mwcs{} problem by combining previously introduced methods for various Steiner tree problems over directed graphs. Their technique was the first to solve to optimality some of the previous benchmark instances and was order of magnitude faster than previous methods on some other instances.

		\Textcite{dittrich2008identifying} were the first to describe a reduction from \mwcs{} to \pcst{} with linear conservation of the objective function optimal value.
		Given this reduction, any method previously proposed to solve the \pcst{} problem could now be used to solve instances of the \mwcs{} problem, application that they demonstrate in system biology for module extraction.
		They also gave an approximation-preserving reduction from \pcst{} to \mwcs{}.
	
		\Textcite{chimani2009obtaining} introduces an ILP formulation equivalent to the \textsc{generalized subtour elimination constraints} formulation proposed by \textcite{lucena2004strong} that they call the \emph{directed cut} formulation.
		They then propose a stronger separation algorithm for this new formulation, which is more efficient in practice than the previous technique introduced by \textcites{fischetti1994weighted}.

	\subsubsection{Direct formulation}

	Direct formulation methods include all methods that can be used to solve the \mwcs{} problem without first explicitly reducing the \mwcs{} instance to a \pcst{} instance.

		%% k-card
	\Textcite{quintao2008integer} provide multiple reformulation of the $k$-cardinality variant of the \mwcs{} problem, from which they formulation strong linear relaxations.
		\Textcite{quintao2010k} further improves the technique by further integrating the constraints introduced very early by \textcite{miller1960integer}.

		\Textcite{backes2012integer} proposed an exact formulation to solve the $k$-cardinality subtrees and connected subgraphs problems.
		See \cref{subsec:activemodules} for details.

		\Textcites{alvarez2013maximum}{alvarez2013rooted} introduced the first technique which does not explicitly model the graph edges.
		Instead they introduce a Branch-and-Cut scheme where connectivity violations are detected from candidate solutions and corresponding constraints are recursively added to the model.
		They showed that their technique outperformed most of the other methods on practical instances at the time.

		\Textcite{el2014solving} introduce new preprocessing rules that they apply until an stable state is obtained.
		They introduce a new graph decomposition, into biconnected and triconnected components, and solve each subproblem using a standard branch-and-cut approach similar to the one introduced by \textcite{alvarez2013maximum}.

		\Textcite{althaus2014algorithms} describe, for $k$-induced subgraph, a combination of \parencite{fischetti1994weighted}, \parencite{chimani2009obtaining}, and \parencite{cohen2010several}.
		%One interesting theoretical result of their paper is that they show that for $k \geq 2$, the polyhedra cannot be compared.
		In their as of yet unpublished manuscript, \textcite{althausalgorithms} further improved their previous algorithm by introducing exact and heuristic reductions of the size of the \mwcs{} instances.
		They solve the newly reduced problems using a combination of two MIP programs formulations: the \parencite{cohen2010several} formulation for spanning tree problems, and the addition of the \emph{generalized subtour elimination constraints} to further reduce the polyhedron size.
		They use \textcite{chimani2009obtaining}'s \emph{directed cut} formulation of the constraints since the separation algorithm for it is very efficient.
		They integrate some of \textcite{el2014solving}'s exact reductions in their algorithm, and propose heuristic reductions if the practical instance is still too large.

%	\subsection{Comparative approaches}
%	\label{subsec:compapproches}
%
%	\Textcite{sharan2006modeling} identify three broad types of comparative approaches:
%	\begin{itemize}
%	\item \emph{Network alignment} methods.
%		They consist in the detection of similar substructures in $k$ different networks, using whole networks comparative techniques.
%		They enable the detection of similar (or dissimilar) structures across the networks.
%
%	\item \emph{Network integration} methods.
%		These methods integrate networks of different types, but defined over the same set of elements, and study their interrelations.
%
%	\item \emph{Network querying} methods.
%		They consist in the detection of one or multiple specific substructures in one network.
%		These substructures can be densely connected subgraphs, for example, or a specific topology that represent a known pathway in another species.
%	\end{itemize}
%
%	Even though network integration is an important aspect of networks comparison (which is used for example for protein interaction prediction \parencite{rhodes2005probabilistic}, or for protein modules detection \parencites{kelley2005systematic}{zhang2005biology}), it is different enough from our core problem that we will not go into details.
%
%	On the other hand, networks alignments and networks querying problems are two sides of the same coin.
%	Indeed, in general terms, network alignment is two seemingly similar subproblems: the \emph{local graph alignment} problem, and the \emph{global graph alignment} problem.
%	Precisely, in the local alignment problem we look for a subgraph in the larger input that most closely resemble a query graph or query criteria.
%	In the global alignment problem we try to match every nodes of one graph to every nodes of the other graph.
%
%	These two subproblem mirror the similarities that exists between the local and global sequence alignment problems.
%	Indeed, similarly to the global sequence alignment problem which is usually used to compare different species or organisms of the same species, the global network alignment problem correspond to the \emph{network alignment} category describe above.
%	And similarly to the local sequence alignment problem which is usually used to compare or locate subsequences, the local network alignment problem correspond to the \emph{network querying} category.
%
%	When looking for matchings networks, vertices are usually mapped on a one-to-one basis, but it can be many-to-one or many-to-many queries.
%	Furthermore, the matching can be weighted, or constrained by a bipartite similarity relationship between the two graphs.
%	They are all optimization problems where some criteria, for example the number of matched nodes or edges, must be maximized.
%
%	First, there are the methods that use the networks in themselves to extract structures deemed interesting.
%	They usually use topological structures of the network in study combined with graph algorithms to detect substructures that are known to appear in targeted biological function.
%
%	However, an interesting problem with biological networks is the detection of similar substructures in $k$ different networks.
%	They can either represent different species or the same species in different conditions.
%	The most simple\footnote{But nonetheless difficult, cf. \cref{subsec:netalignment}.} version of the problem is that of topological alignment, but there exists weighted alignment problems that can be used.
%
%	This section is broken in three independent subsections.
%	First in \cref{subsec:substructure} we present an overview of the topological techniques over biological networks used to infer interesting structures.
%	In \cref{subsec:moduledisc} we provide a detailed look into the module discovery problem, where biological networks and experimental data are combined in order to explain some specific biological process.
%	Finally, in \cref{subsec:netalignment} we look at solutions that look across multiple networks to infer information.
%	In this subsection we will look into technique that explicitly recognize the networks structures through alignment as well as other models.

%		\subsubsection{Network alignment}
%		\label{subsec:netalignment}
%
%		\Textcite{berthier2012cross} found that murine and human responses to lupus nephritis involves similar gene networks.
%		They first derived species-specific networks of significantly differentially expressed genes by using commercial softwares.
%		They used Genomatix GeneSphere software (\url{www.genomatix.de}) to create literature-based networks and Ingenuity Pathway Analysis software (\url{www.ingenuity.com}) to extract canonical pathways.
%		They then determined interesting common subnetworks using a graph matching algorithm.
%
%		\subsubsection{Network querying}
%		\label{subsec:substructure}
%
%
%		\subsection{Combining expression data and comparative techniques}
%		\label{subsec:combining}
